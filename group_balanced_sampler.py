import torch
from torch.utils.data.sampler import Sampler
import random
from collections import defaultdict, Counter
import numpy as np

class GroupBalancedBatchSampler(Sampler):
    """
    Contrastive Learningì„ ìœ„í•œ Batch Sampler.
    
    ê³µí†µ ê¸°ëŠ¥:
        - ê° ë°°ì¹˜ì— (SUPER_GROUP, label) ì¡°í•©ì´ ê°™ì€ ìƒ˜í”Œì„ ìµœì†Œ 2ê°œ(samples_per_group)ì”© í¬í•¨ì‹œí‚µë‹ˆë‹¤.
    
    ëª¨ë“œ ì„¤ì • (use_batch_balance):
        - True: Super Groupì˜ ì‹¤ì œ ë¶„í¬ ë¹„ìœ¨(TARGET_GROUP_RATIOS)ì— ë”°ë¼ í™•ë¥ ì ìœ¼ë¡œ ê·¸ë£¹ì„ ì„ íƒí•©ë‹ˆë‹¤.
        - False: ëª¨ë“  Super Groupì„ ê· ë“±í•œ í™•ë¥ (Uniform)ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
    """
    
    # 14ê°œ ê·¸ë£¹ì— ëŒ€í•œ ì¬êµ¬ì„±ëœ ë¹„ìœ¨
    TARGET_GROUP_RATIOS = {
        'Circulatory': 0.195,
        'Endocrine & Metabolic': 0.131,
        'Symptoms & Signs': 0.084,
        'Respiratory': 0.079,
        'Trauma & Poisoning': 0.076,
        'Digestive': 0.072,
        'Genitourinary': 0.059,
        'Factors & Services': 0.052,
        'Blood & Immune': 0.052,
        'Mental Disorders': 0.050,
        'Nervous System': 0.045,
        'Musculoskeletal & Skin': 0.045,
        'Infectious': 0.037,
        'Neoplasms': 0.025
    }

    def __init__(self, dataset, batch_size, samples_per_group=2, drop_last=False, shuffle=True, 
                 use_batch_balance=True, verbose=True):
        """
        Args:
            use_batch_balance (bool): Trueë©´ ë¹„ìœ¨ ê¸°ë°˜ ìƒ˜í”Œë§, Falseë©´ ê· ë“± ìƒ˜í”Œë§
            verbose (bool): Trueë©´ ë°°ì¹˜ í†µê³„ ì¶œë ¥
        """
        self.dataset = dataset
        self.batch_size = batch_size
        self.samples_per_group = samples_per_group
        self.drop_last = drop_last
        self.shuffle = shuffle
        self.use_batch_balance = use_batch_balance # ëª¨ë“œ ì„ íƒ í”Œë˜ê·¸
        self.verbose = verbose
        
        # ë°ì´í„° ì •ë¦¬
        self.group_label_to_indices = defaultdict(list)
        self.super_group_map = {} 
        
        # ì œì™¸ë˜ê±°ë‚˜ ì•Œ ìˆ˜ ì—†ëŠ” ê·¸ë£¹ ì²˜ë¦¬
        unknown_groups = set()
        
        for idx, item in enumerate(dataset.data_list):
            super_group = item.get('super_group', 'Unknown')
            
            # ë¹„ìœ¨ ì‚¬ì „ì— ì—†ìœ¼ë©´ ìŠ¤í‚µ (True/False ëª¨ë“œ ëª¨ë‘ ë™ì¼í•˜ê²Œ ì ìš©)
            if super_group not in self.TARGET_GROUP_RATIOS:
                continue

            label = item['label'].item() if torch.is_tensor(item['label']) else item['label']
            if isinstance(label, (list, np.ndarray)):
                label = label[0]
            
            key = (super_group, int(label))
            self.group_label_to_indices[key].append(idx)
            self.super_group_map[key] = super_group
        
        self.group_label_keys = list(self.group_label_to_indices.keys())
        
        print(f"[GroupBalancedBatchSampler] Initialized.")
        print(f"  - Mode: {'Weighted Balance (Ratio)' if self.use_batch_balance else 'Uniform Balance'}")
        print(f"  - Valid combinations: {len(self.group_label_keys)}")
        
        # í†µê³„ ì¶œë ¥
        for key in sorted(self.group_label_keys, key=lambda x: (x[1], x[0])):
            group, label = key
            count = len(self.group_label_to_indices[key])
            print(f"    * ({group}, label={label}): {count} samples")

    def __iter__(self):
        # 1. ì¸ë±ìŠ¤ ì…”í”Œë§
        group_label_pools = {}
        for key in self.group_label_keys:
            pool = self.group_label_to_indices[key].copy()
            if self.shuffle:
                random.shuffle(pool)
            group_label_pools[key] = pool
        
        positions = {key: 0 for key in self.group_label_keys}
        batches = []
        
        while True:
            # 2. í˜„ì¬ ìƒ˜í”Œì´ ë‚¨ì•„ìˆëŠ”(Available) ì¡°í•© ì°¾ê¸° (ìµœì†Œ samples_per_group ì´ìƒì¸ ê²ƒë§Œ)
            available_keys = []
            for key in self.group_label_keys:
                remaining = len(group_label_pools[key]) - positions[key]
                if remaining >= self.samples_per_group:
                    available_keys.append(key)
            
            if not available_keys:
                break
            
            # ë°°ì¹˜ì— ë“¤ì–´ê°ˆ ê·¸ë£¹(Key)ì˜ ê°œìˆ˜ ê³„ì‚°
            num_groups_in_batch = self.batch_size // self.samples_per_group
            num_select = min(len(available_keys), num_groups_in_batch)
            
            # 3. ê·¸ë£¹ ì„ íƒ (ì—¬ê¸°ê°€ í•µì‹¬ ë¶„ê¸°ì )
            if self.use_batch_balance:
                # [CASE A] ë¹„ìœ¨ ê¸°ë°˜ í™•ë¥ ì  ì„ íƒ (Weighted Random)
                probs = []
                for key in available_keys:
                    s_group = self.super_group_map[key]
                    weight = self.TARGET_GROUP_RATIOS.get(s_group, 0.01)
                    probs.append(weight)
                
                # ì •ê·œí™”
                probs = np.array(probs)
                if probs.sum() == 0: probs = np.ones(len(probs)) / len(probs)
                else: probs = probs / probs.sum()
                
                if self.shuffle:
                    selected_indices = np.random.choice(len(available_keys), size=num_select, replace=False, p=probs)
                    selected_keys = [available_keys[i] for i in selected_indices]
                else:
                    selected_keys = available_keys[:num_select] # ì…”í”Œ ì•ˆí•˜ë©´ ê·¸ëƒ¥ ì•ì—ì„œë¶€í„°
                    
            else:
                # [CASE B] ê· ë“± ì„ íƒ (Uniform Random) - ê¸°ì¡´ min 2 ë°©ì‹
                # ëª¨ë“  ê·¸ë£¹ì´ ë½‘í í™•ë¥ ì´ ë™ì¼í•¨ (ë°ì´í„° ë§ì€ ê·¸ë£¹ì€ ë‚˜ì¤‘ì— ëª°ë ¤ ë‚˜ì˜´)
                if self.shuffle:
                    selected_keys = random.sample(available_keys, num_select)
                else:
                    selected_keys = available_keys[:num_select]

            # 4. ì„ íƒëœ í‚¤ì—ì„œ ë°ì´í„° ì¶”ì¶œ (ê³µí†µ ë¡œì§)
            batch = []
            for key in selected_keys:
                start_pos = positions[key]
                # ì—¬ê¸°ì„œ ë¬´ì¡°ê±´ samples_per_group(2ê°œ) ë§Œí¼ ìë¦„ -> ìµœì†Œ ê°œìˆ˜ ë³´ì¥
                indices = group_label_pools[key][start_pos:start_pos + self.samples_per_group]
                batch.extend(indices)
                positions[key] += self.samples_per_group
            
            # 5. ë¹ˆ ê³µê°„ ì±„ìš°ê¸° (ìíˆ¬ë¦¬ ê³µê°„)
            # Positive pair ë³´ì¥ì„ ìœ„í•´ ê° ê·¸ë£¹ì—ì„œ ìµœì†Œ 2ê°œì”© ê°€ì ¸ì˜¤ë„ë¡ í•¨
            if len(batch) < self.batch_size:
                # ë¹ˆ ê³µê°„ ì±„ìš¸ ë•ŒëŠ” ëª¨ë“  ê·¸ë£¹ì—ì„œ ììœ ë¡­ê²Œ ì±„ìš°ë˜, ê° ê·¸ë£¹ì—ì„œ ìµœì†Œ 2ê°œì”© ê°€ì ¸ì˜´
                # ë¨¼ì € available_keysì—ì„œ, ê·¸ ë‹¤ìŒ ëª¨ë“  group_label_keysì—ì„œ
                all_keys_to_fill = list(available_keys) + [k for k in self.group_label_keys if k not in available_keys]
                for key in all_keys_to_fill:
                    if len(batch) >= self.batch_size: break
                    rem_in_pool = len(group_label_pools[key]) - positions[key]
                    if rem_in_pool >= self.samples_per_group:
                        # ìµœì†Œ 2ê°œ ì´ìƒ ë‚¨ì•„ìˆìœ¼ë©´ 2ê°œì”© ê°€ì ¸ì˜´ (positive pair ë³´ì¥)
                        take = min(self.batch_size - len(batch), rem_in_pool)
                        # takeê°€ 1ê°œë©´ ë‹¤ìŒ ê·¸ë£¹ìœ¼ë¡œ ë„˜ì–´ê° (positive pair ë³´ì¥ì„ ìœ„í•´)
                        if take < self.samples_per_group:
                            continue
                        start_pos = positions[key]
                        batch.extend(group_label_pools[key][start_pos:start_pos+take])
                        positions[key] += take
                    elif rem_in_pool > 0 and len(batch) + rem_in_pool <= self.batch_size:
                        # ë‚¨ì€ ìƒ˜í”Œì´ 1ê°œì´ê³ , ë°°ì¹˜ í¬ê¸°ë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šìœ¼ë©´ ê°€ì ¸ì˜´
                        # (ì´ ê²½ìš°ëŠ” positive pairê°€ ì—†ì„ ìˆ˜ ìˆì§€ë§Œ, ë°°ì¹˜ í¬ê¸°ë¥¼ ë§ì¶”ê¸° ìœ„í•´)
                        start_pos = positions[key]
                        batch.extend(group_label_pools[key][start_pos:start_pos+rem_in_pool])
                        positions[key] += rem_in_pool

            if len(batch) > 0:
                if self.shuffle: random.shuffle(batch)
                batches.append(batch)
        
        # 6. ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬
        if not self.drop_last:
            remaining_indices = []
            for key in self.group_label_keys:
                start = positions[key]
                remaining_indices.extend(group_label_pools[key][start:])
            
            if remaining_indices:
                if self.shuffle: random.shuffle(remaining_indices)
                for i in range(0, len(remaining_indices), self.batch_size):
                    batch = remaining_indices[i:i + self.batch_size]
                    if len(batch) > 0:
                        batches.append(batch)

        if self.shuffle:
            random.shuffle(batches)
            
        # í†µê³„ ì¶œë ¥ ë° Yield
        for i, batch in enumerate(batches):
            if self.verbose:
                self._print_batch_stats(i, batch)
            yield batch

    def _print_batch_stats(self, batch_idx, batch_indices):
        """ë°°ì¹˜ í†µê³„ ì¶œë ¥"""
        groups = []
        labels = []
        
        for idx in batch_indices:
            item = self.dataset.data_list[idx]
            groups.append(item.get('super_group', 'Unknown'))
            l = item['label']
            if torch.is_tensor(l): l = l.item()
            elif isinstance(l, (list, np.ndarray)): l = l[0]
            labels.append(int(l))
            
        group_counts = Counter(groups)
        label_counts = Counter(labels)
        total = len(batch_indices)
        
        # ë°°ì¹˜ í¬ê¸° í™•ì¸
        expected_size = self.batch_size
        if total != expected_size:
            print(f"\nâš ï¸  [Batch {batch_idx}] Size: {total} (Expected: {expected_size}, Diff: {expected_size - total})")
        else:
            print(f"\nğŸ·ï¸  [Batch {batch_idx}] Size: {total}")
        neg = label_counts.get(0, 0)
        pos = label_counts.get(1, 0)
        print(f"   â””â”€â”€ Label Dist: Neg(0)={neg} ({neg/total*100:.1f}%), Pos(1)={pos} ({pos/total*100:.1f}%)")
        print(f"   â””â”€â”€ Group Dist:")
        sorted_groups = sorted(group_counts.items(), key=lambda x: x[1], reverse=True)
        for g, c in sorted_groups:
            print(f"       - {g}: {c} ({c/total*100:.1f}%)")

    def __len__(self):
        total = sum(len(v) for v in self.group_label_to_indices.values())
        if self.drop_last:
            return total // self.batch_size
        return (total + self.batch_size - 1) // self.batch_size